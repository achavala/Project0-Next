# ğŸ¯ RL SYSTEM FLOW - Visual Diagram

## Complete System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        STEP 1: DATA COLLECTION                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Market Data (SPY)                     â”‚
        â”‚  â€¢ Open, High, Low, Close, Volume      â”‚
        â”‚  â€¢ Last 20 bars (1-minute intervals)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 2: STATE PREPARATION                            â”‚
â”‚                                                                         â”‚
â”‚  Input: Raw market data                                                 â”‚
â”‚  Output: Observation tensor (1, 20, 5)                                  â”‚
â”‚                                                                         â”‚
â”‚  [Bar 1: O=450.0, H=450.5, L=449.8, C=450.2, V=1000000]               â”‚
â”‚  [Bar 2: O=450.2, H=450.8, L=450.1, C=450.6, V=1200000]               â”‚
â”‚  [Bar 3: O=450.6, H=451.0, L=450.4, C=450.9, V=1100000]               â”‚
â”‚  ...                                                                    â”‚
â”‚  [Bar 20: O=452.0, H=452.5, L=451.8, C=452.3, V=1300000]              â”‚
â”‚                                                                         â”‚
â”‚  Shape: (1, 20, 5)  â† Batch dimension for VecEnv                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STEP 3: PPO MODEL PROCESSING                          â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚          SHARED BACKBONE NETWORK                             â”‚     â”‚
â”‚  â”‚                                                               â”‚     â”‚
â”‚  â”‚  Input: (1, 20, 5)                                           â”‚     â”‚
â”‚  â”‚    â†“                                                          â”‚     â”‚
â”‚  â”‚  Flatten: (1, 100)  [20 bars Ã— 5 features]                  â”‚     â”‚
â”‚  â”‚    â†“                                                          â”‚     â”‚
â”‚  â”‚  Dense Layer 1: 64 neurons â†’ ReLU activation                â”‚     â”‚
â”‚  â”‚    â†“                                                          â”‚     â”‚
â”‚  â”‚  Dense Layer 2: 64 neurons â†’ ReLU activation                â”‚     â”‚
â”‚  â”‚    â†“                                                          â”‚     â”‚
â”‚  â”‚  Feature Vector: (1, 64)  â† Learned representations         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚              â†“                         â†“                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  ACTOR NETWORK      â”‚  â”‚  CRITIC NETWORK     â”‚                     â”‚
â”‚  â”‚  (Policy)           â”‚  â”‚  (Value Function)   â”‚                     â”‚
â”‚  â”‚                     â”‚  â”‚                     â”‚                     â”‚
â”‚  â”‚  Feature (64)       â”‚  â”‚  Feature (64)       â”‚                     â”‚
â”‚  â”‚    â†“                â”‚  â”‚    â†“                â”‚                     â”‚
â”‚  â”‚  Dense Layer        â”‚  â”‚  Dense Layer        â”‚                     â”‚
â”‚  â”‚    â†“                â”‚  â”‚    â†“                â”‚                     â”‚
â”‚  â”‚  OUTPUT:            â”‚  â”‚  OUTPUT:            â”‚                     â”‚
â”‚  â”‚  â€¢ Mean (Î¼): -0.3   â”‚  â”‚  â€¢ Value: 0.12     â”‚                     â”‚
â”‚  â”‚  â€¢ Std (Ïƒ): 0.5     â”‚  â”‚    (Expected +12%  â”‚                     â”‚
â”‚  â”‚                     â”‚  â”‚     return)         â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚             â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STEP 4: ACTION SAMPLING (with Entropy)                     â”‚
â”‚                                                                         â”‚
â”‚  Actor Output:                                                          â”‚
â”‚    Mean (Î¼) = -0.3  â† Slight bearish bias                              â”‚
â”‚    Std (Ïƒ) = 0.5   â† Randomness/exploration level                      â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚  Sampling Methods:                       â”‚                         â”‚
â”‚  â”‚                                          â”‚                         â”‚
â”‚  â”‚  Deterministic=True (Live Trading):      â”‚                         â”‚
â”‚  â”‚    action_raw = Î¼ = -0.3  â† No randomnessâ”‚                         â”‚
â”‚  â”‚                                          â”‚                         â”‚
â”‚  â”‚  Deterministic=False (Training):         â”‚                         â”‚
â”‚  â”‚    action_raw ~ N(Î¼=-0.3, Ïƒ=0.5)        â”‚                         â”‚
â”‚  â”‚    = -0.45  (example sample)             â”‚                         â”‚
â”‚  â”‚                                          â”‚                         â”‚
â”‚  â”‚  Clip to [-1.0, 1.0]:                   â”‚                         â”‚
â”‚  â”‚    action_raw = -0.45  â† Final value    â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                         â”‚
â”‚  Entropy Controls Randomness:                                          â”‚
â”‚    â€¢ High entropy (Ïƒ large) â†’ More exploration                         â”‚
â”‚    â€¢ Low entropy (Ïƒ small) â†’ More exploitation                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 5: ACTION MAPPING                               â”‚
â”‚                                                                         â”‚
â”‚  Input: action_raw = -0.45 (continuous)                                 â”‚
â”‚                                                                         â”‚
â”‚  Mapping Logic:                                                         â”‚
â”‚    if abs(action_raw) < 0.35:                                           â”‚
â”‚        action = 0  # HOLD                                               â”‚
â”‚    elif action_raw > 0:                                                 â”‚
â”‚        action = 1  # BUY CALL                                           â”‚
â”‚    else:                                                                â”‚
â”‚        action = 2  # BUY PUT                                            â”‚
â”‚                                                                         â”‚
â”‚  For action_raw = -0.45:                                                â”‚
â”‚    abs(-0.45) = 0.45 > 0.35  âœ“ Not HOLD                                â”‚
â”‚    -0.45 < 0  âœ“ Negative                                               â”‚
â”‚    â†’ action = 2  # BUY PUT                                              â”‚
â”‚                                                                         â”‚
â”‚  If position exists and action_raw >= 0.5:                              â”‚
â”‚    if action_raw < 0.75:                                                â”‚
â”‚        action = 3  # TRIM 50%                                           â”‚
â”‚    elif action_raw < 0.9:                                               â”‚
â”‚        action = 4  # TRIM 70%                                           â”‚
â”‚    else:                                                                â”‚
â”‚        action = 5  # FULL EXIT                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                STEP 6: CONSTRAINT LAYER (Human Control)                 â”‚
â”‚                                                                         â”‚
â”‚  Input: action = 2 (BUY PUT)                                            â”‚
â”‚                                                                         â”‚
â”‚  Apply Constraints:                                                     â”‚
â”‚    âœ“ Check if action violates human rules                               â”‚
â”‚    âœ“ Block early exits before TP1                                       â”‚
â”‚    âœ“ Enforce stop losses                                                â”‚
â”‚    âœ“ Respect position limits                                            â”‚
â”‚                                                                         â”‚
â”‚  Example Constraint:                                                    â”‚
â”‚    if action in [3, 4, 5] and pnl < 0.40:                               â”‚
â”‚        action = 0  # Force HOLD (too early to exit)                     â”‚
â”‚                                                                         â”‚
â”‚  Output: action = 2  (No constraint violation)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 7: TRADE EXECUTION                              â”‚
â”‚                                                                         â”‚
â”‚  Action: 2 (BUY PUT)                                                    â”‚
â”‚                                                                         â”‚
â”‚  Execution Steps:                                                       â”‚
â”‚    1. Find ATM strike: $452 (current price)                            â”‚
â”‚    2. Calculate position size: 5 contracts                             â”‚
â”‚    3. Get option symbol: SPY251205P00452000                            â”‚
â”‚    4. Submit order to Alpaca:                                          â”‚
â”‚       â€¢ Symbol: SPY251205P00452000                                     â”‚
â”‚       â€¢ Quantity: 5                                                    â”‚
â”‚       â€¢ Side: BUY                                                      â”‚
â”‚       â€¢ Type: MARKET                                                   â”‚
â”‚    5. Track position in risk_mgr.open_positions                        â”‚
â”‚                                                                         â”‚
â”‚  Order Status: âœ“ FILLED                                                 â”‚
â”‚  Entry Premium: $0.45                                                   â”‚
â”‚  Entry Price: $452.30                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STEP 8: POSITION MONITORING & EXITS                        â”‚
â”‚                                                                         â”‚
â”‚  Every 30-60 seconds:                                                   â”‚
â”‚    1. Check Stop Losses:                                                â”‚
â”‚       â€¢ Absolute -15% stop (highest priority)                          â”‚
â”‚       â€¢ Hard stop -35%                                                  â”‚
â”‚       â€¢ Normal stop -20%                                                â”‚
â”‚                                                                         â”‚
â”‚    2. Check Take Profits:                                               â”‚
â”‚       â€¢ TP1: +40% â†’ Sell 50%                                           â”‚
â”‚       â€¢ TP2: +80% â†’ Sell 60% of remaining                              â”‚
â”‚       â€¢ TP3: +150% â†’ Full exit                                         â”‚
â”‚                                                                         â”‚
â”‚    3. Check Trailing Stops:                                             â”‚
â”‚       â€¢ After TP1/TP2: Trail at TP - 20%                               â”‚
â”‚                                                                         â”‚
â”‚  Example:                                                               â”‚
â”‚    Current Premium: $0.68 (+51% profit)                                â”‚
â”‚    TP1 Triggered: Sell 50% (2.5 contracts)                             â”‚
â”‚    Remaining: 2.5 contracts                                            â”‚
â”‚    Trail Stop Activated: Exit 80% at TP1 - 20% = +20%                  â”‚
â”‚    Runner: 0.5 contracts until EOD or -15% stop                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 9: REWARD CALCULATION                           â”‚
â”‚                    (Only During Training)                               â”‚
â”‚                                                                         â”‚
â”‚  Reward Components:                                                     â”‚
â”‚    â€¢ Realized P&L: +$125 (2.5 contracts Ã— $0.23 profit)                â”‚
â”‚    â€¢ Sharpe Ratio: 2.5                                                  â”‚
â”‚    â€¢ Win Rate: 75%                                                      â”‚
â”‚    â€¢ Drawdown: -5%                                                      â”‚
â”‚                                                                         â”‚
â”‚  Reward Formula:                                                        â”‚
â”‚    reward = (pnl/capital Ã— 10) + (sharpe Ã— 0.1) +                      â”‚
â”‚             (win_rate Ã— 0.2) - (drawdown Ã— 0.5)                        â”‚
â”‚                                                                         â”‚
â”‚    reward = (125/100000 Ã— 10) + (2.5 Ã— 0.1) +                          â”‚
â”‚             (0.75 Ã— 0.2) - (0.05 Ã— 0.5)                                â”‚
â”‚    reward = 0.0125 + 0.25 + 0.15 - 0.025 = 0.3875                      â”‚
â”‚                                                                         â”‚
â”‚  This reward is used to update the PPO model weights                   â”‚
â”‚  (Only happens during training, not live trading)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Components Explained

### 1. Observation (State)
- **Shape:** (1, 20, 5) = Batch Ã— Bars Ã— Features
- **Content:** Last 20 bars of OHLCV data
- **Purpose:** Represents current market condition

### 2. PPO Model
- **Actor:** Outputs action distribution (mean + std)
- **Critic:** Estimates expected return from state
- **Shared Backbone:** Learns feature representations

### 3. Action Sampling
- **Deterministic=True:** Uses mean only (no randomness)
- **Deterministic=False:** Samples from distribution (has randomness)
- **Entropy:** Controls exploration vs exploitation

### 4. Action Mapping
- **Continuous â†’ Discrete:** -1.0 to +1.0 â†’ 0-5
- **Interpretation:** HOLD, BUY CALL, BUY PUT, TRIM, EXIT

### 5. Constraints
- **Human Rules:** Block unwanted behaviors
- **Priority:** Stop losses > TP system > RL actions
- **Preserves Randomness:** Constrains final action, not raw output

### 6. Execution
- **Real Trading:** Via Alpaca API
- **Position Tracking:** In `risk_mgr.open_positions`
- **Risk Management:** Position sizing, limits, safeguards

### 7. Rewards (Training Only)
- **Components:** P&L, Sharpe, win rate, drawdown
- **Purpose:** Update model weights to improve performance
- **Not Used Live:** Live trading uses pre-trained weights

---

## Entropy & Randomness Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           TRAINING (Exploration Mode)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
    Actor Output: Î¼=-0.3, Ïƒ=0.5
              â”‚
              â†“
    Sample: action_raw ~ N(-0.3, 0.5)
              â”‚
              â†“
    Result: action_raw = -0.45 (random)
              â”‚
              â†“
    Map: action = 2 (BUY PUT)
              â”‚
              â†“
    Execute: Buy 5 PUT contracts
              â”‚
              â†“
    Calculate Reward: Based on outcome
              â”‚
              â†“
    Update Model: Learn from experience


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LIVE TRADING (Exploitation Mode)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
    Actor Output: Î¼=-0.3, Ïƒ=0.5
              â”‚
              â†“
    Deterministic: action_raw = Î¼ = -0.3 (no randomness)
              â”‚
              â†“
    Map: action = 2 (BUY PUT)
              â”‚
              â†“
    Constraints: Check human rules
              â”‚
              â†“
    Execute: Buy 5 PUT contracts (if allowed)
```

---

## Controlling Without Losing Randomness

### Method 1: Constraint Layer (Recommended)

```
Raw Action (with randomness) â†’ Constraint Check â†’ Final Action
     â†“                              â†“
  action = 5                   if pnl < 0.40:
  (FULL EXIT)                     action = 0 (HOLD)
```

**Benefits:**
- âœ… Keeps randomness in raw output
- âœ… Applies human rules after sampling
- âœ… No retraining needed

### Method 2: Reward Shaping

```
Bad Action â†’ Negative Reward â†’ Model Learns to Avoid
```

**Benefits:**
- âœ… Model learns preferred behavior
- âœ… Requires retraining
- âœ… More permanent change

### Method 3: RLHF (Full Control)

```
Human Preferences â†’ Reward Model â†’ Shaped Rewards â†’ Better Policy
```

**Benefits:**
- âœ… Complete control over behavior
- âœ… Complex to implement
- âœ… Requires preference data

---

**This diagram shows the complete flow from market data to trade execution!**

